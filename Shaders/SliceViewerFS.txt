#version 120

#extension GL_ARB_texture_rectangle : enable
#ifdef GL_EXT_gpu_shader4
#extension GL_EXT_gpu_shader4 : enable
#endif

uniform sampler3D volume;
uniform vec3 volumeOrigin;
uniform vec3 volumeSize;
uniform float volumeDataShift;
uniform float volumeDataScale;

uniform float viewportX;
uniform float viewportY;
uniform int objectId;

struct FeatureVector
{
	float v[MFE_PROPERTYCOUNT];
};

struct Mask
{
	bool v[MFE_ORIGINALPROPERTYCOUNT];
};

struct FeatureDefinition
{
	bool enabled;
	vec3 examplePos;
	float startThreshold;
	float endThreshold;
	float power;
	float stretch;
	vec3 color;
	vec3 backgroundPos;
	bool biasRelativeToMean;
	Mask mask;
	float dimFrac;
};

uniform float dataTransform[MFE_PROPERTYCOUNT * MFE_ORIGINALPROPERTYCOUNT];
uniform float dataMean[MFE_ORIGINALPROPERTYCOUNT];
uniform float dataMin[MFE_ORIGINALPROPERTYCOUNT];
uniform float dataMax[MFE_ORIGINALPROPERTYCOUNT];
uniform FeatureDefinition userFeatures[MFE_FEATURECOUNT];
uniform int numActiveFeatures;

struct Feature
{
	int defId; // index into the userFeatures uniform
	FeatureVector example;
	FeatureVector bias;
	float delta;
};

FeatureVector getFeatureVector(vec3 pos)
{
	FeatureVector result;
	vec4 tpos = gl_TextureMatrixInverse[0] * vec4(pos, 1.0);
	vec3 p = ((tpos.xyz / tpos.w) - volumeOrigin) / volumeSize;
	vec4 comps = vec4(volumeDataShift) + 
		volumeDataScale * texture3D(volume, p);
	for (int i = 0; i < 4; ++i)
	{
		if (i < MFE_PROPERTYCOUNT) result.v[i] = comps[i];
	}

	return result;
}

FeatureVector project(FeatureVector x, Mask m)
{
	// Project to original space
	float x2[MFE_ORIGINALPROPERTYCOUNT];
	for (int i = 0; i < MFE_ORIGINALPROPERTYCOUNT; ++i)
	{
		x2[i] = 0.0;
		// Only unmasked dimensions
		if (m.v[i])
		{
			for (int j = 0; j < MFE_PROPERTYCOUNT; ++j)
			{
				x2[i] += x.v[j] * dataTransform[i + j * MFE_ORIGINALPROPERTYCOUNT];
			}
		}
	}
	// Project back to the reduced feature space
	FeatureVector result;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		result.v[i] = 0.0;
		for (int j = 0; j < MFE_ORIGINALPROPERTYCOUNT; ++j)
		{
			result.v[i] += x2[j] * dataTransform[j + i * MFE_ORIGINALPROPERTYCOUNT];
		}
	}
	return result;
}

FeatureVector stretch(FeatureVector x, FeatureVector v, float s, float dimFrac)
{
	// Volume-preserving scaling with respect to the original feature subspace 
	// left after the masking projection

	// Uniformly scale entire space
	float s2 = 1.0 / pow(s, dimFrac);
	// Matrix-vector multiplication with the scaling matrix
	FeatureVector result;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		result.v[i] = 0.0;
		for (int j = 0; j < MFE_PROPERTYCOUNT; ++j)
		{
			float Mij = (s - 1.0) * v.v[i] * v.v[j];
			if (i == j) Mij += 1.0;
			result.v[i] += Mij * s2 * x.v[j];
		}
	}
	return result;
}

float distance(FeatureVector a, FeatureVector b, float power)
{
	float sum = 0.0;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		sum += pow(abs(a.v[i] - b.v[i]), power);
	}
	return pow(sum, 1.0/power);
}

float getValue(Feature f, FeatureVector fv)
{
	// Feature vectors are projected, then stretched
	FeatureVector fvt = stretch(
		project(fv, userFeatures[f.defId].mask), 
		f.bias, userFeatures[f.defId].stretch, 
		userFeatures[f.defId].dimFrac);
	// Compute distance
	return distance(f.example, fvt, userFeatures[f.defId].power);
}

float getValue(Feature f, vec3 pos)
{
	// Get FeatureVector
	FeatureVector fv = getFeatureVector(pos);
	// Compute distance
	return getValue(f, fv);
}

bool isInside(Feature f, float val)
{
	// TODO: adjust threshold based on f.delta
	return val < pow(10.0, userFeatures[f.defId].startThreshold) * 
		userFeatures[f.defId].endThreshold;
}

float dotTexture(vec2 c)
{
	return length(mod(c, 20.0) - vec2(10.0)) < 5.0 ? 0.0 : 1.0;
}

void main()
{
	// Screen coords
	vec2 sc = gl_FragCoord.xy;
	sc.x -= viewportX;
	sc.y -= viewportY;

	// Sample volume
	vec3 pos = gl_TexCoord[0].xyz;
	FeatureVector fv = getFeatureVector(pos);

	// Project the featurevector to the original space
	float originalfv[MFE_ORIGINALPROPERTYCOUNT];
	for (int j = 0; j < MFE_ORIGINALPROPERTYCOUNT; ++j)
	{
		for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
		{
			originalfv[j] += fv.v[i] * 
				dataTransform[j + i * MFE_ORIGINALPROPERTYCOUNT];
		}
		// Values are centered on the mean
		// Scale values to [-1..1] using min and max
		float absmax = max(abs(dataMean[j] - dataMin[j]), abs(dataMax[j] - dataMean[j]));
		originalfv[j] /= absmax;
	}

	// Visualize the feature vector
	vec4 color = vec4(vec3(0.0), 1.0);
	vec3 colors[8];
	colors[0] = vec3(1.0, 0.0, 0.0);
	colors[1] = vec3(0.0, 1.0, 0.0);
	colors[2] = vec3(0.0, 0.0, 1.0);
	colors[3] = vec3(1.0, 0.5, 0.0);
	colors[4] = vec3(0.0, 0.5, 1.0);
	colors[5] = vec3(1.0, 0.0, 0.5);
	colors[6] = vec3(0.5, 0.0, 1.0);
	colors[7] = vec3(1.0, 1.0, 1.0);
	for (int i = 1; i < MFE_ORIGINALPROPERTYCOUNT; ++i)
	{
		color.rgb += mix(vec3(0.0), colors[min(i, 7)], abs(originalfv[i])) / float(MFE_ORIGINALPROPERTYCOUNT);
	}
	color.rgb = vec3(0.3) + color.rgb;

	// Set up features
	Feature features[MFE_FEATURECOUNT];
	for (int f = 0; f < MFE_FEATURECOUNT; ++f)
	{
		// Link to feature definition
		if (f < numActiveFeatures && userFeatures[f].enabled)
		{
			features[f].defId = f;
		}
		else
		{
			// Default to 0 to hopefully hit some cache
			features[f].defId = 0;
		}
	}

	// Example-based feature definitions
	for (int f = 0; f < MFE_FEATURECOUNT; ++f)
	{
		// Compute example
		features[f].example = 
			getFeatureVector(userFeatures[f].examplePos);
		// Compute background feature vector
		FeatureVector bg = getFeatureVector(userFeatures[f].backgroundPos);
		if (f < numActiveFeatures && userFeatures[f].enabled)
		{
			if (userFeatures[f].biasRelativeToMean)
			{
				for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
				{
					bg.v[i] = 0.0;
				}
			}
			// Compute bias vector
			for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
			{
				// Bias towards difference
				features[f].bias.v[i] = features[f].example.v[i] - bg.v[i];
			}
			// Project to subspace defined by the mask
			features[f].bias = project(features[f].bias, userFeatures[f].mask);
			// Compute length
			float l = 0.0;
			for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
			{
				l += features[f].bias.v[i] * features[f].bias.v[i];
			}
			l = sqrt(l);
			features[f].delta = l;
			// Normalize
			l = 1.0 / l;
			for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
			{
				features[f].bias.v[i] = features[f].bias.v[i] * l;
			}
			// Pre-transform example
			features[f].example = stretch(
				project(features[f].example, userFeatures[f].mask), 
				features[f].bias, userFeatures[f].stretch, 
				userFeatures[f].dimFrac);
		}
	}

	// Visualize the features
	for (int f = 0; f < MFE_FEATURECOUNT; ++f)
	{
		if (f < numActiveFeatures && userFeatures[f].enabled)
		{
			float value = getValue(features[f], fv);
			if (isInside(features[f], value))
			{
				float bla = 1.0 - (value - userFeatures[f].startThreshold) /
					(userFeatures[f].endThreshold - 
						userFeatures[f].startThreshold);
				color.rgb = mix(color.rgb, (0.2 + 0.8 * bla) * userFeatures[f].color, 0.7);
				// TODO: contours might be nice
			}
		}
	}

	// Use black for positions outside the volume
	vec3 tc = (pos - volumeOrigin) / volumeSize;
	for (int i = 0; i < 3; ++i)
	{
		if (tc[i] < 0.0 || tc[i] > 1.0)
		{
			color = vec4(vec3(0.0), 1.0);
		}
	}

	gl_FragColor = vec4(color.rgb, color.a);
}
