#version 120

#extension GL_ARB_texture_rectangle : enable
#ifdef GL_EXT_gpu_shader4
#extension GL_EXT_gpu_shader4 : enable
#endif

uniform sampler2DRect info0Previous;
uniform sampler2DRect info0Current;
uniform sampler2DRect info1Current;
uniform sampler2DRect info2Current;

uniform int layer;
uniform float viewportX;
uniform float viewportY;

uniform sampler3D volume[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform float volumeDataShift[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform float volumeDataScale[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeOrigin[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeSize[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeSpacing[NQVTK_RAYCASTER_VOLUMECOUNT];

uniform float stepSize;
uniform float kernelSize;

struct FeatureVector
{
	float v[MFE_PROPERTYCOUNT];
};

struct Mask
{
	bool v[MFE_ORIGINALPROPERTYCOUNT];
};

struct FeatureDefinition
{
	bool enabled;
	vec3 examplePos;
	float startThreshold;
	float endThreshold;
	float power;
	float stretch;
	vec3 color;
	vec3 backgroundPos;
	bool biasRelativeToMean;
	Mask mask;
	int numDims;
};

uniform float dataTransform[MFE_PROPERTYCOUNT * MFE_ORIGINALPROPERTYCOUNT];
uniform FeatureDefinition userFeatures[MFE_FEATURECOUNT];
uniform int numActiveFeatures;

struct Feature
{
	int defId; // index into the userFeatures uniform
	FeatureVector example;
	FeatureVector bias;
	float delta;
	float projection[MFE_PROPERTYCOUNT * MFE_PROPERTYCOUNT];
};

// Prototypes from LibUtility
vec3 phongShading(vec3 matColor, vec3 normal);
bool getBit(float byte, int bit);
float setBit(float byte, int bit, bool on);

FeatureVector getFeatureVector(vec3 pos)
{
	FeatureVector result;

	const int numVolumes = (MFE_PROPERTYCOUNT + 3) / 4;
	// Only a single volume is supported for now...
	int v = 0;
	vec4 tpos = gl_TextureMatrixInverse[v] * vec4(pos, 1.0);
	vec3 p = ((tpos.xyz / tpos.w) - volumeOrigin[v]) / volumeSize[v];
	vec4 comps = vec4(volumeDataShift[v]) + 
		volumeDataScale[v] * texture3D(volume[v], p);
	for (int i = 0; i < 4; ++i)
	{
		int c = v * 4 + i;
		if (c < MFE_PROPERTYCOUNT) result.v[c] = comps[i];
	}
	return result;
}

FeatureVector project(FeatureVector x, Feature f)
{
	// Project to subspace defined by the mask
	FeatureVector result;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		result.v[i] = 0.0;
		for (int j = 0; j < MFE_PROPERTYCOUNT; ++j)
		{
			result.v[i] += x.v[i] * f.projection[j + i * MFE_PROPERTYCOUNT];
		}
	}
	return result;
}

FeatureVector stretch(FeatureVector x, FeatureVector v, float s, int numDims)
{
	// Volume-preserving scaling with respect to the original feature subspace 
	// left after the masking projection

	// We uniformly scale the entire space, then scale along the vector
	// First compute the required scaling factors such that s1 * s2 == s
	float s1 = s;
	float s2 = 1.0;
	if (numDims > 1)
	{
		s2 = 1.0 / pow(s, 1.0 / float(numDims - 1));
		s1 = s / s2;
	}
	// Matrix-vector multiplication with the scaling matrix
	FeatureVector result;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		result.v[i] = 0.0;
		for (int j = 0; j < MFE_PROPERTYCOUNT; ++j)
		{
			float Mij = (s1 - 1.0) * v.v[i] * v.v[j];
			if (i == j) Mij += 1.0;
			result.v[i] += Mij * s2 * x.v[j];
		}
	}
	return result;
}

float distance(FeatureVector a, FeatureVector b, float power)
{
	float sum = 0.0;
	for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
	{
		sum += pow(abs(a.v[i] - b.v[i]), power);
	}
	return pow(sum, 1.0/power);
}

float getValue(Feature f, FeatureVector fv)
{
	// Feature vectors are projected, then stretched
	FeatureVector fvt = stretch(project(fv, f), 
		f.bias, userFeatures[f.defId].stretch, 
		userFeatures[f.defId].numDims);
	// Compute distance
	return distance(f.example, fvt, userFeatures[f.defId].power);
}

float getValue(Feature f, vec3 pos)
{
	// Get FeatureVector
	FeatureVector fv = getFeatureVector(pos);
	// Compute distance
	return getValue(f, fv);
}

// Compute gradient of the volume
vec3 computeGradient(Feature f, vec3 pos, float delta, float val)
{
#ifdef NQVTK_RAYCASTER_CENTRALDIFFERENCES
	float dx = (getValue(f, pos + vec3(0.5 * delta, 0.0, 0.0)) - 
		getValue(f, pos - vec3(0.5 * delta, 0.0, 0.0))) / delta;
	float dy = (getValue(f, pos + vec3(0.0, 0.5 * delta, 0.0)) - 
		getValue(f, pos - vec3(0.0, 0.5 * delta, 0.0))) / delta;
	float dz = (getValue(f, pos + vec3(0.0, 0.0, 0.5 * delta)) - 
		getValue(f, pos - vec3(0.0, 0.0, 0.5 * delta))) / delta;
#else
	float dx = (getValue(f, pos + vec3(delta, 0.0, 0.0)) - val) / delta;
	float dy = (getValue(f, pos + vec3(0.0, delta, 0.0)) - val) / delta;
	float dz = (getValue(f, pos + vec3(0.0, 0.0, delta)) - val) / delta;
#endif
	return vec3(dx, dy, dz);
}

bool isInside(Feature f, float val)
{
	// Adjust thresholding based on f.delta
	float v = val / f.delta / userFeatures[f.defId].stretch;
	float start = userFeatures[f.defId].startThreshold;
	float end = userFeatures[f.defId].endThreshold;
	bool inside;
	if (start < end)
	{
		// Satisfy both thresholds
		inside = v >= start && v <= end;
	}
	else
	{
		// Either threshold will work
		inside = v >= start || v <= end;
	}
	return inside;
}

vec3 refineHitpoint(Feature f, vec3 pos, vec3 step, bool insideAtPos)
{
	vec3 s = 0.5 * step;
	vec3 p = pos - s;
	// 6 refinements should be enough for now
	for (int r = 0; r < 6; ++r) {
		float val = getValue(f, p);
		// Halve the step size
		s *= 0.5;
		// Step in which direction?
		if (isInside(f, val) == insideAtPos) {
			p -= s;
		} else {
			p += s;
		}
	}
	return p;
}

void main()
{
	// Get info
	vec4 r0 = gl_FragCoord;
	r0.x -= viewportX;
	r0.y -= viewportY;
	vec4 infoAfter = texture2DRect(info0Current, r0.xy);

	// Discard background
	if (length(infoAfter) == 0.0) discard;

	vec4 infoBefore = texture2DRect(info0Previous, r0.xy);
	vec4 normalid = texture2DRect(info1Current, r0.xy);
	vec3 normal = normalize(normalid.rgb);
	float gm = length(normalid.rgb);
	int id = int(normalid.a) - 1;
	vec4 color = texture2DRect(info2Current, r0.xy);
	vec4 info = infoAfter;
	// TODO: adjust for any non-volume meshes in the scene
	int fidbase = NQVTK_RAYCASTER_VOLUMECOUNT;

	// Raycast into the slab
	vec3 startPos = infoBefore.rgb;
	vec3 endPos = infoAfter.rgb;
	vec3 ray = endPos - startPos;

	if (length(ray) > 0) 
	{
		// Determine step, number of steps
		vec3 step = normalize(ray) * stepSize;
		vec3 normalStep = step;
		float stepLength = stepSize;
		int numSteps = int(ceil(length(ray) / stepSize));

		Feature features[MFE_FEATURECOUNT];
		for (int f = 0; f < MFE_FEATURECOUNT; ++f)
		{
			// Link to feature definition
			if (f < numActiveFeatures && userFeatures[f].enabled)
			{
				features[f].defId = f;
			}
			else
			{
				// Default to 0 to hopefully hit some cache
				features[f].defId = 0;
			}
		}

		// Example-based feature definitions
		for (int f = 0; f < MFE_FEATURECOUNT; ++f)
		{
			// Compute example
			features[f].example = 
				getFeatureVector(userFeatures[f].examplePos);
			// Compute background feature vector
			FeatureVector bg = getFeatureVector(userFeatures[f].backgroundPos);
			if (f < numActiveFeatures && userFeatures[f].enabled)
			{
				// Compute projection matrix for the feature's mask
				for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
				{
					for (int j = i; j < MFE_PROPERTYCOUNT; ++j)
					{
						features[f].projection[j + i * MFE_PROPERTYCOUNT] = 0.0;
						for (int k = 0; k < MFE_ORIGINALPROPERTYCOUNT; ++k)
						{
							if (userFeatures[f].mask.v[k])
							{
								features[f].projection[j + i * MFE_PROPERTYCOUNT] += 
									dataTransform[k + i * MFE_ORIGINALPROPERTYCOUNT] * 
									dataTransform[k + j * MFE_ORIGINALPROPERTYCOUNT];
							}
						}
						// Symmetric matrix
						if (i != j)
						{
							features[f].projection[i + j * MFE_PROPERTYCOUNT] = 
								features[f].projection[j + i * MFE_PROPERTYCOUNT];
						}
					}
				}
				// The mean is at the origin
				if (userFeatures[f].biasRelativeToMean)
				{
					for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
					{
						bg.v[i] = 0.0;
					}
				}
				// Project the feature vectors to the subspace defined by the mask
				features[f].example = project(features[f].example, features[f]);
				bg = project(bg, features[f]);
				// Compute the bias vector
				for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
				{
					// Bias towards difference
					features[f].bias.v[i] = features[f].example.v[i] - bg.v[i];
				}
				// Compute length
				float l = 0.0;
				for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
				{
					l += features[f].bias.v[i] * features[f].bias.v[i];
				}
				l = sqrt(l);
				features[f].delta = l;
				// Normalize
				l = 1.0 / l;
				for (int i = 0; i < MFE_PROPERTYCOUNT; ++i)
				{
					features[f].bias.v[i] = features[f].bias.v[i] * l;
				}
				// Pre-stretch example
				features[f].example = stretch(features[f].example,
					features[f].bias, userFeatures[f].stretch, 
					userFeatures[f].numDims);
			}
		}

		// Start raycasting
		vec3 pos = startPos;
		bool active[MFE_FEATURECOUNT];
		bool insideAtStart[MFE_FEATURECOUNT];
		bool hit[MFE_FEATURECOUNT];
		vec3 refined[MFE_FEATURECOUNT];
		vec3 gradient[MFE_FEATURECOUNT];
		// Conditional sampler indices are not supported by current hardware, 
		// so multi-fields are limited to fully overlapping volumes...
		bool inVolume = getBit(infoBefore.a, 0);
		for (int f = 0; f < MFE_FEATURECOUNT; ++f)
		{
			active[f] = f < numActiveFeatures && 
				userFeatures[f].enabled && inVolume;
			insideAtStart[f] = getBit(infoBefore.a, f + fidbase);
			hit[f] = false;
			refined[f] = vec3(0.0);
			gradient[f] = vec3(0.0);
		}
		int hitFeature = -1;
		// For each step along the ray...
		for (int i = 0; i < numSteps + 1 && hitFeature < 0; ++i)
		{
			// Get featurevector for the current position
			FeatureVector fv = getFeatureVector(pos);
			// Loop over features
			for (int f = 0; f < MFE_FEATURECOUNT; ++f)
			{
				// If the feature is active, test for intersections
				if (active[f])
				{
					float val = getValue(features[f], fv);
					bool insideAtPos = isInside(features[f], val);
					if (insideAtPos != insideAtStart[f])
					{
						// Found an isosurface, so this is the last step
						hit[f] = true;
						hitFeature = f;
						// Refine the hit for this volume
						refined[f] = refineHitpoint(features[f], pos, 
							normalStep, insideAtPos);
						// Compute gradient
						// NOTE: we can't optimize this out, as volume[v] is currently 
						// only possible for deterministic v (constant or for-loop)
#ifdef NQVTK_RAYCASTER_CENTRALDIFFERENCES
						gradient[f] = computeGradient(features[f], refined[f], 
							kernelSize, 0.0);
#else
						gradient[f] = computeGradient(features[f], refined[f], 
							kernelSize, getValue(features[f], refined[f]));
#endif
					}
				}
			}
			// The last step should stay within the slab
			if (i == numSteps)
			{
				step = endPos - pos;
				stepLength = length(step);
			}
			// Step along the ray
			pos += step;
		}

		// If we found one or more surfaces, determine the closest one
		if (hitFeature >= 0)
		{
			int nearestF = hitFeature;
			float nearestD = length(refined[hitFeature] - startPos);
			for (int f = 0; f < MFE_FEATURECOUNT; ++f)
			{
				if (hit[f])
				{
					float d = length(refined[f] - startPos);
					if (d < nearestD)
					{
						nearestF = f;
						nearestD = d;
					}
				}
			}
			// Update infobuffers based on this hit
			// The refined position can be on either side of the surface, but
			// pos is definitely on the other side, but we store refined + step 
			// instead so we have "accurate" positions in the painter stage
			id = nearestF + fidbase;
			info = vec4(refined[nearestF] + normalStep, 
				setBit(infoBefore.a, id, !insideAtStart[nearestF]));
			color = vec4(userFeatures[nearestF].color, 0.7);
			normal = gradient[nearestF];
			if (dot(normal, step) > 0.0) normal = -normal;
			normal = gl_NormalMatrix * normal;
		}
	}

	// Fill the infobuffer
	gl_FragData[0] = info;
	gl_FragData[1] = vec4(normal, float(id + 1));
	gl_FragData[2] = color;
}
