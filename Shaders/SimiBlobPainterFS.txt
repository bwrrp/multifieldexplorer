#version 120

#extension GL_ARB_texture_rectangle : enable
#ifdef GL_EXT_gpu_shader4
#extension GL_EXT_gpu_shader4 : enable
#endif

uniform sampler2DRect info0Previous;
uniform sampler2DRect info0Current;
uniform sampler2DRect info1Current;
uniform sampler2DRect info2Current;

uniform int layer;
uniform float viewportX;
uniform float viewportY;
uniform vec3 cameraPos;

uniform sampler3D volume[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform float volumeDataShift[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform float volumeDataScale[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeOrigin[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeSize[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform vec3 volumeSpacing[NQVTK_RAYCASTER_VOLUMECOUNT];

uniform float tfStart[NQVTK_RAYCASTER_VOLUMECOUNT];
uniform float tfEnd[NQVTK_RAYCASTER_VOLUMECOUNT];

uniform float testParam;

uniform float occlusionEdgeThreshold;
uniform float cornerEdgeThreshold;

// Prototypes from LibUtility
vec3 phongShading(vec3 matColor, vec3 normal);
bool getBit(float byte, int bit);

float stripes(float f, int size, int part)
{
	return int(f) % size < part ? 0.0 : 1.0;
}

float plusTexture(vec2 c)
{
	return 1.0 - stripes(c.x, 20, 8) * stripes(c.y, 20, 8) * 
		(1.0 - stripes(c.x + 8.0, 20, 4) * stripes(c.y + 8.0, 20, 4));
}

float minusTexture(vec2 c)
{
	return 1.0 - stripes(c.x, 20, 8) * 
		(1.0 - stripes(c.y + 8.0, 20, 4));
}

float stripeTexture(vec2 c)
{
	return stripes(abs(c.x + c.y), 20, 8);
}

float dotTexture(vec2 c)
{
	return length(mod(c, 20.0) - vec2(10.0)) < 5.0 ? 0.0 : 1.0;
}

bool ignoreObject(int id)
{
	// TODO: adjust for any non-volume meshes in the scene
	return id < NQVTK_RAYCASTER_VOLUMECOUNT;
}

struct sample
{
	vec2 coord;

	vec3 pos;
	float inOut;

	vec3 posPrevious;
	float inOutPrevious;

	vec3 normal;
	float gm;
	int id;

	vec4 color;
};

sample getBasicSample(vec2 coord)
{
	sample result;
	result.coord = coord;
	vec4 info = texture2DRect(info0Current, coord);
	result.pos = info.rgb;
	result.inOut = info.a;
	return result;
}

sample samplePrevious(sample basicSample)
{
	sample result = basicSample;
	vec4 info = texture2DRect(info0Previous, basicSample.coord);
	if (layer == 0) info = vec4(0.0);
	result.posPrevious = info.rgb;
	result.inOutPrevious = info.a;
	return result;
}

sample sampleNormalId(sample basicSample)
{
	sample result = basicSample;
	vec4 normalid = texture2DRect(info1Current, basicSample.coord);
	result.normal = normalize(normalid.rgb);
	result.gm = length(normalid.rgb);
	result.id = int(normalid.a) - 1;
	return result;
}

sample sampleColor(sample basicSample)
{
	sample result = basicSample;
	result.color = texture2DRect(info2Current, basicSample.coord);
	return result;
}

sample getFullSample(vec2 coord)
{
	sample result = getBasicSample(coord);
	result = samplePrevious(result);
	result = sampleNormalId(result);
	result = sampleColor(result);
	return result;
}

vec4 shadeFragment(sample fragment)
{
	vec4 color = fragment.color;

	// TODO: adjust for any non-volume meshes in the scene
	int fidbase = NQVTK_RAYCASTER_VOLUMECOUNT;

	// Some extra coloring effects for volume features
	if (length(fragment.pos) > 0.0)
	{
		if ((getBit(fragment.inOutPrevious, fidbase) && 
			getBit(fragment.inOutPrevious, fidbase + 1)) != 
			(getBit(fragment.inOut, fidbase) && 
			getBit(fragment.inOut, fidbase + 1)))
		{
			color.a = 1.0;
		}
		else if (fragment.id == fidbase || fragment.id == fidbase + 1)
		{
			color.rgb = mix(color.rgb, vec3(1.0), 0.5);
		}
	}

	/* Test: screen-space normals
	sample fx = getBasicSample(fragment.coord + testParam * 10.0 * vec2(1.0, 0.0));
	sample fy = getBasicSample(fragment.coord + testParam * 10.0 * vec2(0.0, 1.0));
	vec3 vx = fx.pos - fragment.pos;
	vec3 vy = fy.pos - fragment.pos;
	fragment.normal = gl_NormalMatrix * normalize(cross(vx, vy));
	//*/

	// Simple lighting
	if (fragment.gm > 0.0)
	{
		color = vec4(phongShading(color.rgb, fragment.normal), color.a);
	}

	//* SSAO test
	float z = distance(cameraPos, fragment.pos);
	if (fragment.id >= 0)
	{
		int n = 40;
		int n2 = n / 4;
		int step = max(1, n / 10);
		float offset = 0.3;
		float ambocc = 0.0;
		float ambocc2 = 0.0;
		int count = 0;
		int count2 = 0;
		for (int i = -n; i <= n; i += step)
		{
			for (int j = -n; j <= n; j += step)
			{
				sample fragment2 = getFullSample(fragment.coord + vec2(i, j));
				float z2 = distance(cameraPos, fragment2.pos);
				if (fragment2.id < 0) z2 = 10000.0;
				float delta = (z - z2 - offset) * 0.05;
				float occlusion = delta > 0.0 ? 1.0 / (1.0 + delta * delta) : 0.0;
				// Decrease occlusion contribution from transparent surfaces
				occlusion *= 1.0 - pow(1.0 - fragment2.color.a, 2.0);
				ambocc += occlusion;
				++count;
				if (abs(i) <= n2 && abs(j) <= n2)
				{
					ambocc2 += occlusion;
					++count2;
				}
			}
		}
		ambocc /= float(count);
		ambocc2 /= float(count2);
		color.rgb *= 1.0 - max(ambocc, ambocc2);
	}
	//*/

	/* Test: screen-space textures for visualizing ids
	if (fragment.id == fidbase) {
		color.rgb *= (0.5 + 0.5 * stripeTexture(fragment.coord));
	} else if (fragment.id == fidbase + 1) {
		color.rgb *= (0.5 + 0.5 * plusTexture(fragment.coord));
	} else if (fragment.id == fidbase + 2) {
		color.rgb *= (0.5 + 0.5 * minusTexture(fragment.coord));
	}
	//*/
	//if (fragment.id > fidbase) color.a = 1.0;
	//if (fragment.id == fidbase + 3) color.a = 0.2;

	/* Test: vector direction visualization
	if (fragment.id == fidbase + 3 || fragment.id == fidbase + 5)
	{
		vec4 tpos = gl_TextureMatrixInverse[0] * vec4(fragment.pos, 1.0);
		vec3 p = ((tpos.xyz / tpos.w) - volumeOrigin[0]) / volumeSize[0];
		vec3 dir = vec3(volumeDataShift[0]) + volumeDataScale[0] * texture3D(volume[0], p).xyz;
		dir = gl_NormalMatrix * normalize(dir);
		vec2 d = dir.xy; 
		if (fragment.id == fidbase + 3) 
			d = (dir - dot(dir, fragment.normal) * fragment.normal).xy;
		//* Smearing
		int n = 0;
		float f = 0.0;
		float wtot = 0.0;
		int imax = 50;
		for (int i = 0; i < imax; ++i)
		{
			vec2 tc = fragment.coord + float(i - imax) * d;
			float w = pow(float(i) / float(imax), 2.0);
			if (i == imax - 1) f += dotTexture(tc) * 3.0;
			f += dotTexture(tc) * w;
			wtot += w;
			++n;
		}
		f /= wtot;
		//if (f < 0.8) f = 0.0;
		color.rgb *= f;
		//color.a = 0.1 + 0.4 * f;
	}
	//*/

	//* Apply contouring
	const int NB_SIZE = 4;
	vec2 nb[NB_SIZE];
	nb[0] = fragment.coord + vec2(-1.0,  0.0);
	nb[1] = fragment.coord + vec2( 1.0,  0.0);
	nb[2] = fragment.coord + vec2( 0.0, -1.0);
	nb[3] = fragment.coord + vec2( 0.0,  1.0);
	// Collect samples
	sample nbs[NB_SIZE];
	for (int i = 0; i < NB_SIZE; ++i)
	{
		nbs[i] = getBasicSample(nb[i]);
		nbs[i] = sampleNormalId(nbs[i]);
	}
	// Detect silhouettes
	bool silhouette = false;
	bool ignoreSilhouette = true;
	vec3 viewDir = normalize(fragment.pos - cameraPos);
	for (int i = 0; i < NB_SIZE; ++i)
	{
		// TODO: these positions are not refined surface hits!
		vec3 posdiff = nbs[i].pos - fragment.pos;
		// Background contains 0 positions and needs special care
		bool bgsil = fragment.id < 0 ^^ nbs[i].id < 0;
		if (length(posdiff) > occlusionEdgeThreshold || bgsil)
		{
			silhouette = true;
			// Determine frontmost
			// Note that id and nbIds[i] can't both be background
			int frontmost;
			if ((!bgsil && dot(viewDir, posdiff) > 0.0) || 
				(bgsil && fragment.id >= 0))
			{
				frontmost = fragment.id;
			}
			else
			{
				frontmost = nbs[i].id;
			}
			// Ignore silhouette if all frontmost objects are ignored
			ignoreSilhouette = ignoreSilhouette && ignoreObject(frontmost);
		}
	}
	if (silhouette)
	{
		if (!ignoreSilhouette) color = vec4(0.0, 0.0, 0.0, 1.0);
	}
	else
	{
		bool intersection = false;
		bool ignoreIntersection = true;
		for (int i = 0; i < NB_SIZE; ++i)
		{
			if (nbs[i].id != fragment.id)
			{
				intersection = true;
				// Ignore intersection if the object is ignored
				ignoreIntersection = ignoreIntersection && ignoreObject(nbs[i].id);
			}
		}
		// Also ignore intersections if the current object is ignored
		ignoreIntersection = ignoreIntersection || ignoreObject(fragment.id);
		if (intersection)
		{
			if (!ignoreIntersection) color = vec4(0.0, 0.0, 0.3, 1.0);
		}
		else
		{
			// All ids are the same, only draw corners if the object is not ignored
			if (!ignoreObject(fragment.id))
			{
				// Detect corners
				bool corner = false;
				for (int i = 0; i < NB_SIZE; ++i)
				{
					if (abs(dot(normalize(nbs[i].normal), fragment.normal)) < 
						cornerEdgeThreshold)
					{
						corner = true;
					}
				}
				if (corner)
				{
					color = vec4(0.0, 0.3, 0.0, 1.0);
				}
			}
		}
	}
	//*/

	// Premultiply colors
	return vec4(color.rgb * color.a, color.a);
}

void main()
{
	// Get coordinate
	vec2 r0 = gl_FragCoord.xy;
	r0.x -= viewportX;
	r0.y -= viewportY;

	// Get fragment info
	sample fragment = getFullSample(r0);

	// Apply deferred shading
	vec4 color = shadeFragment(fragment);

	/* DoF test
	float focusDist = distance(cameraPos, vec3(-5.0, -5.0, 5.0));
	const float maxZ = 20.0;
	float z = abs(distance(cameraPos, fragment.pos) - focusDist);
	if (fragment.id < 0 || z > maxZ) z = maxZ;
	int n = int(z);
	int count = 1;
	int step = max(1, n / 4);
	// TODO: we should actually loop over the maximum blur size for the neighborhood
	for (int i = -n; i <= n; i += step)
	{
		for (int j = -n; j <= n; j += step)
		{
			sample fragment2 = getFullSample(r0 + vec2(i, j));
			float z2 = abs(distance(cameraPos, fragment2.pos) - focusDist);
			if (fragment2.id < 0 || z2 > maxZ) z2 = maxZ;
			int n2 = int(z2);
			if (n2 > 0 && !(i == 0 && j == 0) && abs(i) <= n2 && abs(j) <= n2)
			{
				color += shadeFragment(fragment2);
				++count;
			}
		}
	}
	color /= float(count);
	//*/

	gl_FragColor = color;
}
